{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7251,"sourceType":"datasetVersion","datasetId":2798},{"sourceId":377107,"sourceType":"datasetVersion","datasetId":165566},{"sourceId":9051514,"sourceType":"datasetVersion","datasetId":5457553}],"dockerImageVersionId":29271,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install imutils\npip install efficientnet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T10:53:51.548012Z","iopub.execute_input":"2024-04-22T10:53:51.548365Z","iopub.status.idle":"2024-04-22T10:54:00.356784Z","shell.execute_reply.started":"2024-04-22T10:53:51.548302Z","shell.execute_reply":"2024-04-22T10:54:00.355999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport cv2\nimport os\nimport shutil\nimport itertools\nimport imutils\nimport matplotlib.pyplot as plt\n\n# from sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\n\n# from tensorflow.keras.applications import EfficientNetB0, preprocess_input\n\nfrom keras import layers\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping\n\ninit_notebook_mode(connected=True)\nRANDOM_SEED = 123","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:00.359203Z","iopub.execute_input":"2024-04-22T10:54:00.359562Z","iopub.status.idle":"2024-04-22T10:54:04.088062Z","shell.execute_reply.started":"2024-04-22T10:54:00.359498Z","shell.execute_reply":"2024-04-22T10:54:04.08716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T10:54:04.089673Z","iopub.execute_input":"2024-04-22T10:54:04.089941Z","iopub.status.idle":"2024-04-22T10:54:05.050388Z","shell.execute_reply.started":"2024-04-22T10:54:04.08989Z","shell.execute_reply":"2024-04-22T10:54:05.049445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = '../input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/'\n\nfor CLASS in os.listdir(IMG_PATH):\n   \n    IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n\n    for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n\n        img = IMG_PATH + CLASS + '/' + FILE_NAME\n\n        if n < 0.2*IMG_NUM:\n            shutil.copy(img, 'TEST/' + CLASS.upper() + '/' + FILE_NAME)\n        elif n < 0.8*IMG_NUM:\n            shutil.copy(img, 'TRAIN/'+ CLASS.upper() + '/' + FILE_NAME)\n        else:\n            shutil.copy(img, 'VAL/'+ CLASS.upper() + '/' + FILE_NAME)\n            \n            \nprint('Directories are successfully made!')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:05.052016Z","iopub.execute_input":"2024-04-22T10:54:05.052282Z","iopub.status.idle":"2024-04-22T10:54:06.132571Z","shell.execute_reply.started":"2024-04-22T10:54:05.052241Z","shell.execute_reply":"2024-04-22T10:54:06.131817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\ndef load_data(dir_path, img_size=(100, 100)):\n    X = []\n    y = []\n    labels = {}\n\n    for i, class_name in enumerate(sorted(os.listdir(dir_path))):\n        if not class_name.startswith('.'):\n            labels[i] = class_name\n            class_path = os.path.join(dir_path, class_name)\n            for file in sorted(os.listdir(class_path)):\n                if not file.startswith('.'):\n                    img = cv2.imread(os.path.join(class_path, file))\n#                     img = cv2.resize(img, img_size)\n                    X.append(img)\n                    y.append(i)\n\n    X = np.array(X)\n    y = np.array(y)\n\n    print(f'{len(X)} images loaded from {dir_path} directory.')\n    return X, y, labels\n\n\n\ndef plot_confusion_matrix(cm, classes):\n    plt.figure(figsize= (5,5))\n    plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Greens)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation= 45)\n    plt.yticks(tick_marks, classes)\n\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T10:54:06.13584Z","iopub.execute_input":"2024-04-22T10:54:06.136074Z","iopub.status.idle":"2024-04-22T10:54:06.151989Z","shell.execute_reply.started":"2024-04-22T10:54:06.136035Z","shell.execute_reply":"2024-04-22T10:54:06.151185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = 'TRAIN/'\nTEST_DIR = 'TEST/'\nVAL_DIR = 'VAL/'\nIMG_SIZE = (224,224)\n\n# use predefined function to load the image data into workspace\nX_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\nX_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\nX_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:06.154703Z","iopub.execute_input":"2024-04-22T10:54:06.154962Z","iopub.status.idle":"2024-04-22T10:54:06.716208Z","shell.execute_reply.started":"2024-04-22T10:54:06.154913Z","shell.execute_reply":"2024-04-22T10:54:06.715354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport pandas as pd\n\nsets = ['Train Set', 'Validation Set', 'Test Set']\nclasses = [0, 1]\ncounts = [[np.sum(y_train == c) for c in classes],\n          [np.sum(y_val == c) for c in classes],\n          [np.sum(y_test == c) for c in classes]]\n\ndf = pd.DataFrame(counts, columns=classes)\ndf['Set'] = sets\ndf_melted = df.melt(id_vars='Set', var_name='Class', value_name='Count')\n\nfig = px.bar(df_melted, x='Set', y='Count', color='Class', \n             barmode='group', title='Count of classes in each set',\n             color_discrete_sequence=['#33cc33', '#ff3300'])\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:06.717491Z","iopub.execute_input":"2024-04-22T10:54:06.717765Z","iopub.status.idle":"2024-04-22T10:54:08.363461Z","shell.execute_reply.started":"2024-04-22T10:54:06.717713Z","shell.execute_reply":"2024-04-22T10:54:08.362619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index in range(len(labels)):\n    imgs = X_train[np.argwhere(y_train == index)][:10]\n    j = 5\n    i = int(10/j)\n\n    plt.figure(figsize=(15,5))\n    c = 1\n    for img in imgs:\n        plt.subplot(i,j,c)\n        plt.imshow(img[0])\n\n        plt.xticks([])\n        plt.yticks([])\n        c += 1\n    plt.suptitle(f'Tumor: {labels[index]}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:08.364885Z","iopub.execute_input":"2024-04-22T10:54:08.365135Z","iopub.status.idle":"2024-04-22T10:54:09.676147Z","shell.execute_reply.started":"2024-04-22T10:54:08.365094Z","shell.execute_reply":"2024-04-22T10:54:09.674986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_imgs(set_name, add_pixels_value=0):\n\n    set_new = []\n    for img in set_name:\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n        # threshold the image, then perform a series of erosions +\n        # dilations to remove any small regions of noise\n        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n        thresh = cv2.erode(thresh, None, iterations=2)\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # find contours in thresholded image, then grab the largest one\n        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnts = imutils.grab_contours(cnts)\n        c = max(cnts, key=cv2.contourArea)\n\n        # find the extreme points\n        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n        extRight = tuple(c[c[:, :, 0].argmax()][0])\n        extTop = tuple(c[c[:, :, 1].argmin()][0])\n        extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n        ADD_PIXELS = add_pixels_value\n        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n        set_new.append(new_img)\n\n    return np.array(set_new)\n\n# apply this for each set\nX_train_crop = crop_imgs(set_name=X_train)\nX_val_crop = crop_imgs(set_name=X_val)\nX_test_crop = crop_imgs(set_name=X_test)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T10:54:09.678141Z","iopub.execute_input":"2024-04-22T10:54:09.678853Z","iopub.status.idle":"2024-04-22T10:54:09.937684Z","shell.execute_reply.started":"2024-04-22T10:54:09.678773Z","shell.execute_reply":"2024-04-22T10:54:09.936677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index in range(len(labels)):\n    imgs = X_train_crop[np.argwhere(y_train == index)][:10]\n    j = 5\n    i = int(10/j)\n\n    plt.figure(figsize=(15,5))\n    c = 1\n    for img in imgs:\n        plt.subplot(i,j,c)\n        plt.imshow(img[0])\n\n        plt.xticks([])\n        plt.yticks([])\n        c += 1\n    plt.suptitle(f'Tumor: {labels[index]}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:09.939307Z","iopub.execute_input":"2024-04-22T10:54:09.939685Z","iopub.status.idle":"2024-04-22T10:54:11.206242Z","shell.execute_reply.started":"2024-04-22T10:54:09.939623Z","shell.execute_reply":"2024-04-22T10:54:11.205049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_new_images(x_set, y_set, folder_name):\n    i = 0\n    for (img, imclass) in zip(x_set, y_set):\n        if imclass == 0:\n            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)\n        else:\n            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)\n        i += 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T10:54:11.208101Z","iopub.execute_input":"2024-04-22T10:54:11.20872Z","iopub.status.idle":"2024-04-22T10:54:11.219321Z","shell.execute_reply.started":"2024-04-22T10:54:11.208653Z","shell.execute_reply":"2024-04-22T10:54:11.218312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving new images to the folder\n!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES VAL_CROP/NO\n\nsave_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\nsave_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\nsave_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:11.221055Z","iopub.execute_input":"2024-04-22T10:54:11.221435Z","iopub.status.idle":"2024-04-22T10:54:12.487567Z","shell.execute_reply.started":"2024-04-22T10:54:11.221389Z","shell.execute_reply":"2024-04-22T10:54:12.486454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_imgs(set_name, img_size):\n    set_new = []\n    for img in set_name:\n        img = cv2.resize(\n            img,\n            dsize=img_size,\n            interpolation=cv2.INTER_CUBIC\n        )\n        set_new.append(preprocess_input(img))\n    return np.array(set_new)\n\nX_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\nX_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\nX_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T10:54:12.489478Z","iopub.execute_input":"2024-04-22T10:54:12.489837Z","iopub.status.idle":"2024-04-22T10:54:12.974004Z","shell.execute_reply.started":"2024-04-22T10:54:12.489773Z","shell.execute_reply":"2024-04-22T10:54:12.973342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set the paramters we want to change randomly\ndemo_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    rescale=1./255,\n    shear_range=0.05,\n    brightness_range=[0.1, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:12.975397Z","iopub.execute_input":"2024-04-22T10:54:12.975648Z","iopub.status.idle":"2024-04-22T10:54:12.980694Z","shell.execute_reply.started":"2024-04-22T10:54:12.975607Z","shell.execute_reply":"2024-04-22T10:54:12.979944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('preview', exist_ok=True)\nx = X_train_crop[5].reshape((1,) + X_train_crop[5].shape)\n\nfor i, batch in enumerate(demo_datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='aug_img', save_format='jpg')):\n    if i >= 20:\n        break\n\nplt.figure(figsize=(10, 5))\nplt.subplot(2, 5, 1)\nplt.imshow(X_train_crop[5])\nplt.title('Original Image')\nplt.axis('off')\n\nfor i, img_file in enumerate(os.listdir('preview/')[:9]):\n    img = cv2.cvtColor(cv2.imread(os.path.join('preview', img_file)), cv2.COLOR_BGR2RGB)\n    plt.subplot(2, 5, i + 2)\n    plt.imshow(img)\n    plt.axis('off')\n\nplt.suptitle('Augmented Images')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:12.981845Z","iopub.execute_input":"2024-04-22T10:54:12.982107Z","iopub.status.idle":"2024-04-22T10:54:13.840155Z","shell.execute_reply.started":"2024-04-22T10:54:12.982058Z","shell.execute_reply":"2024-04-22T10:54:13.839362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = 'TRAIN_CROP/'\nVAL_DIR = 'VAL_CROP/'\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    brightness_range=[0.5, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True,\n    preprocessing_function=preprocess_input\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)\n\n\nvalidation_generator = test_datagen.flow_from_directory(\n    VAL_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=16,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:13.841796Z","iopub.execute_input":"2024-04-22T10:54:13.842118Z","iopub.status.idle":"2024-04-22T10:54:14.060516Z","shell.execute_reply.started":"2024-04-22T10:54:13.842067Z","shell.execute_reply":"2024-04-22T10:54:14.059611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic CNN Model","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = 1\nmodel = Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224,224,3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\n# Freeze convolutional layers\nfor layer in model.layers[:-3]:\n    layer.trainable = False\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=1e-4),\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:14.061942Z","iopub.execute_input":"2024-04-22T10:54:14.062236Z","iopub.status.idle":"2024-04-22T10:54:14.239563Z","shell.execute_reply.started":"2024-04-22T10:54:14.062168Z","shell.execute_reply":"2024-04-22T10:54:14.238797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define number of epochs\nEPOCHS = 25\n\n# Train the model\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=40,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=25\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T10:54:14.240983Z","iopub.execute_input":"2024-04-22T10:54:14.241222Z","iopub.status.idle":"2024-04-22T11:01:28.490029Z","shell.execute_reply.started":"2024-04-22T10:54:14.241171Z","shell.execute_reply":"2024-04-22T11:01:28.489164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model performance\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:01:28.494124Z","iopub.execute_input":"2024-04-22T11:01:28.494448Z","iopub.status.idle":"2024-04-22T11:01:29.332967Z","shell.execute_reply.started":"2024-04-22T11:01:28.49439Z","shell.execute_reply":"2024-04-22T11:01:29.331287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\ntarget_names = ['yes','no']\ncm = confusion_matrix(y_test, predictions)\nplot_confusion_matrix(cm= cm, classes= target_names)\nprint(classification_report(y_test, predictions, target_names= target_names))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:01:29.33525Z","iopub.execute_input":"2024-04-22T11:01:29.336023Z","iopub.status.idle":"2024-04-22T11:01:29.992543Z","shell.execute_reply.started":"2024-04-22T11:01:29.335796Z","shell.execute_reply":"2024-04-22T11:01:29.98951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG Net","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16, preprocess_input\n\nvgg16_weight_path = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = VGG16(\n    weights=vgg16_weight_path,\n    include_top=False, \n    input_shape=IMG_SIZE + (3,)\n)\n\nNUM_CLASSES = 1\n\nvgg_model = Sequential()\nvgg_model.add(base_model)\nvgg_model.add(layers.Flatten())\nvgg_model.add(layers.Dropout(0.5))\nvgg_model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\nvgg_model.layers[0].trainable = False\n\nvgg_model.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=1e-4),\n    metrics=['accuracy']\n)\n\nvgg_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:01:29.994997Z","iopub.execute_input":"2024-04-22T11:01:29.995498Z","iopub.status.idle":"2024-04-22T11:01:31.364595Z","shell.execute_reply.started":"2024-04-22T11:01:29.995422Z","shell.execute_reply":"2024-04-22T11:01:31.363386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25\n\nhistory = vgg_model.fit_generator(\n    train_generator,\n    steps_per_epoch=50,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=25\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-22T12:15:01.08678Z","iopub.execute_input":"2024-04-22T12:15:01.087116Z","iopub.status.idle":"2024-04-22T12:24:11.493607Z","shell.execute_reply.started":"2024-04-22T12:15:01.087069Z","shell.execute_reply":"2024-04-22T12:24:11.492735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model performance\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T12:27:23.323121Z","iopub.execute_input":"2024-04-22T12:27:23.323564Z","iopub.status.idle":"2024-04-22T12:27:23.976654Z","shell.execute_reply.started":"2024-04-22T12:27:23.323499Z","shell.execute_reply":"2024-04-22T12:27:23.975565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = vgg_model.predict(X_test_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\ntarget_names = ['yes','no']\ncm = confusion_matrix(y_test, predictions)\nplot_confusion_matrix(cm= cm, classes= target_names)\nprint(classification_report(y_test, predictions, target_names= target_names))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T12:27:27.554146Z","iopub.execute_input":"2024-04-22T12:27:27.554485Z","iopub.status.idle":"2024-04-22T12:27:28.093909Z","shell.execute_reply.started":"2024-04-22T12:27:27.554436Z","shell.execute_reply":"2024-04-22T12:27:28.092747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom numpy import expand_dims\n\n\n# load the model\nmodel = VGG16()\n# redefine model to output right after the first hidden layer\nixs = [2, 5, 9, 13, 17]\noutputs = [model.layers[i].output for i in ixs]\nmodel = Model(inputs=model.inputs, outputs=outputs)\n# load the image with the required shape\n# convert the image to an array\nimg = img_to_array(X_val_prep[43])\n# expand dimensions so that it represents a single 'sample'\nimg = expand_dims(img, axis=0)\n# prepare the image (e.g. scale pixel values for the vgg)\nimg = preprocess_input(img)\n# get feature map for first hidden layer\nfeature_maps = model.predict(img)\n# plot the output from each block\nsquare = 8\nfor fmap in feature_maps:\n    # plot all 64 maps in an 8x8 squares\n    ix = 1\n    for _ in range(square):\n        plt.figure(figsize=(64,64))\n        for _ in range(square):\n           \n\n            # specify subplot and turn of axis\n            ax = plt.subplot(square, square, ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n\n            # plot filter channel in grayscale\n            plt.imshow(fmap[0, :, :, ix-1], cmap='viridis')\n            ix += 1\n    # show the figure\n\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:08:53.741532Z","iopub.execute_input":"2024-04-22T11:08:53.742235Z","iopub.status.idle":"2024-04-22T11:10:12.963762Z","shell.execute_reply.started":"2024-04-22T11:08:53.741874Z","shell.execute_reply":"2024-04-22T11:10:12.962346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature maps from earlier layers tend to capture low-level features like edges, textures, or simple shapes, while feature maps from deeper layers capture higher-level features or complex patterns relevant to the task the network was trained on.\n\n","metadata":{}},{"cell_type":"markdown","source":"# ResNet","metadata":{}},{"cell_type":"code","source":"# ResNet\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\n\nresnet_weight_path = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet_base_model = ResNet50(\n    weights=resnet_weight_path,\n    include_top=False, \n    input_shape=IMG_SIZE + (3,)\n)\n\nresnet_model = Sequential()\nresnet_model.add(resnet_base_model)\nresnet_model.add(layers.Flatten())\nresnet_model.add(layers.Dropout(0.5))\nresnet_model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\nresnet_model.layers[0].trainable = False\n\nresnet_model.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=1e-4),\n    metrics=['accuracy']\n)\n\nresnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:10:12.965672Z","iopub.execute_input":"2024-04-22T11:10:12.966043Z","iopub.status.idle":"2024-04-22T11:10:27.941637Z","shell.execute_reply.started":"2024-04-22T11:10:12.965978Z","shell.execute_reply":"2024-04-22T11:10:27.940668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25\nes = EarlyStopping(\n    monitor='val_acc', \n    mode='max',\n    patience=6\n)\n\nhistory = resnet_model.fit_generator(\n    train_generator,\n    steps_per_epoch=40,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=25,\n#     callbacks=[es]\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:19:24.354529Z","iopub.execute_input":"2024-04-22T11:19:24.354915Z","iopub.status.idle":"2024-04-22T11:26:41.248095Z","shell.execute_reply.started":"2024-04-22T11:19:24.354855Z","shell.execute_reply":"2024-04-22T11:26:41.246859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model performance\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:28:02.536227Z","iopub.execute_input":"2024-04-22T11:28:02.536571Z","iopub.status.idle":"2024-04-22T11:28:02.952959Z","shell.execute_reply.started":"2024-04-22T11:28:02.536525Z","shell.execute_reply":"2024-04-22T11:28:02.952002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = resnet_model.predict(X_test_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\ntarget_names = ['yes','no']\ncm = confusion_matrix(y_test, predictions)\nplot_confusion_matrix(cm= cm, classes= target_names)\nprint(classification_report(y_test, predictions, target_names= target_names))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:28:19.882882Z","iopub.execute_input":"2024-04-22T11:28:19.883241Z","iopub.status.idle":"2024-04-22T11:28:20.233149Z","shell.execute_reply.started":"2024-04-22T11:28:19.883168Z","shell.execute_reply":"2024-04-22T11:28:20.232248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inception Net","metadata":{}},{"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\n\n# InceptionNet\ninception_weight_path = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\ninception_base_model = InceptionV3(\n    weights=inception_weight_path,\n    include_top=False, \n    input_shape=IMG_SIZE + (3,)\n)\n\ninception_model = Sequential()\ninception_model.add(inception_base_model)\ninception_model.add(layers.GlobalAveragePooling2D())\ninception_model.add(layers.Dropout(0.5))\ninception_model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\ninception_model.layers[0].trainable = False\n\ninception_model.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=1e-4),\n    metrics=['accuracy']\n)\n\ninception_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:28:30.168866Z","iopub.execute_input":"2024-04-22T11:28:30.169226Z","iopub.status.idle":"2024-04-22T11:28:55.59087Z","shell.execute_reply.started":"2024-04-22T11:28:30.169152Z","shell.execute_reply":"2024-04-22T11:28:55.590126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25\n\nhistory = inception_model.fit_generator(\n    train_generator,\n    steps_per_epoch=40,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=25\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:29:05.048312Z","iopub.execute_input":"2024-04-22T11:29:05.048636Z","iopub.status.idle":"2024-04-22T11:36:22.450547Z","shell.execute_reply.started":"2024-04-22T11:29:05.048575Z","shell.execute_reply":"2024-04-22T11:36:22.449092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model performance\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:36:22.453989Z","iopub.execute_input":"2024-04-22T11:36:22.454514Z","iopub.status.idle":"2024-04-22T11:36:23.027617Z","shell.execute_reply.started":"2024-04-22T11:36:22.45445Z","shell.execute_reply":"2024-04-22T11:36:23.02223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = inception_model.predict(X_test_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\ntarget_names = ['yes','no']\ncm = confusion_matrix(y_test, predictions)\nplot_confusion_matrix(cm= cm, classes= target_names)\nprint(classification_report(y_test, predictions, target_names= target_names))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:54:12.323154Z","iopub.execute_input":"2024-04-22T11:54:12.323554Z","iopub.status.idle":"2024-04-22T11:54:12.858978Z","shell.execute_reply.started":"2024-04-22T11:54:12.323502Z","shell.execute_reply":"2024-04-22T11:54:12.857877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom efficientnet.tfkeras import EfficientNetB3, preprocess_input\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\nbase_model = EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\neff_model = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(2, activation='softmax')\n])\n\noptimizer = tf.keras.optimizers.Adam()\n# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\neff_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\neff_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:54:23.857539Z","iopub.execute_input":"2024-04-22T11:54:23.857791Z","iopub.status.idle":"2024-04-22T11:54:48.084426Z","shell.execute_reply.started":"2024-04-22T11:54:23.85775Z","shell.execute_reply":"2024-04-22T11:54:48.083603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = eff_model.fit_generator(\n    train_generator,\n    steps_per_epoch=40,\n    epochs=25,\n    validation_data=validation_generator,\n    verbose=1,\n    validation_steps=25\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-22T11:54:48.086063Z","iopub.execute_input":"2024-04-22T11:54:48.086418Z","iopub.status.idle":"2024-04-22T12:02:58.752328Z","shell.execute_reply.started":"2024-04-22T11:54:48.086356Z","shell.execute_reply":"2024-04-22T12:02:58.751314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model performance\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T12:02:58.755424Z","iopub.execute_input":"2024-04-22T12:02:58.755816Z","iopub.status.idle":"2024-04-22T12:02:59.490689Z","shell.execute_reply.started":"2024-04-22T12:02:58.755747Z","shell.execute_reply":"2024-04-22T12:02:59.489686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = eff_model.predict(X_test_prep)\npredictions = [1 if x[1]>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\ntarget_names = ['yes','no']\ncm = confusion_matrix(y_test, predictions)\nplot_confusion_matrix(cm= cm, classes= target_names)\nprint(classification_report(y_test, predictions, target_names= target_names))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T12:03:29.832637Z","iopub.execute_input":"2024-04-22T12:03:29.832945Z","iopub.status.idle":"2024-04-22T12:03:30.203834Z","shell.execute_reply.started":"2024-04-22T12:03:29.8329Z","shell.execute_reply":"2024-04-22T12:03:30.202858Z"},"trusted":true},"execution_count":null,"outputs":[]}]}